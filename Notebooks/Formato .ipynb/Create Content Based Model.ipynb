{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d37cd0",
   "metadata": {},
   "source": [
    "### Creación del modelo basado en contenido\n",
    "Este notebook recorta el dataset del películas original, ya que no es factible calcular las similitudes entre cada par de películas con más de 45000 películas (requiere un espacio excesivo de memoria para nuestros equipos, aunque sea sólo en cálculos intermedios). Para recortar el datset nos quedamos con el 33% de las películas más populares (que más valoraciones tienen). Con las 14732 películas correspondientes a ese porcentaje sí que hemos podido trabajar sin problema.\n",
    "\n",
    "\n",
    "A partir de este dataset se crea una tabla Nx(N-1) (en formato Numpy Array), cuya i-ésima fila consta de los IDs de las demás películas (todas salvo la número i) ordenados de mayor a menor similitud con la película i. Esta tabla constituye el modelo basado en contenido y se almacena en un fichero externo para ser utilizada por el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ccb96",
   "metadata": {},
   "source": [
    "Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfdef6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afbb20",
   "metadata": {},
   "source": [
    "Cargamos y limpiar el dataset de películas según explican paso por paso los comentarios del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db156d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones originales: (45466, 24)\n",
      "Cuantil de voto 0.66: 20.0\n",
      "Dimensiones tras quitar películas: (14732, 24)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el dataset\n",
    "df_movies_original = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "#Mostramos sus dimensiones\n",
    "print(\"Dimensiones originales:\",df_movies_original.shape)\n",
    "\n",
    "# En 'id' hay algunos valores no numéricos, descartamos esas filas\n",
    "df_movies_original = df_movies_original[df_movies_original['id'].apply(lambda x: str(x).isdigit())]\n",
    "\n",
    "# Hay ids repetidos en el dataset de películas. Nos quedamos sólo con uno de ellos\n",
    "df_movies_original = df_movies_original.drop_duplicates(subset = ['id'])\n",
    "\n",
    "# También ahy películas diferentes con títulos idénticos.Nos quedamos con solo una de ellas\n",
    "df_movies_original = df_movies_original.drop_duplicates(subset = ['title'])\n",
    "\n",
    "#Quitamos la película titulada \"A movie\" pues es un problema en el dialogo con el usuario\n",
    "df_movies_original = df_movies_original[df_movies_original['title'] != 'A Movie']\n",
    "\n",
    "# Fijamos un cuantil de 0.66 para quedarnos solo con el 33% de las películas más votadas\n",
    "quantile = 0.66\n",
    "# Calculamos el valor a partir del cual solo quedan por encima el 33% de las películas\n",
    "vote_quantile = df_movies_original[\"vote_count\"].quantile(quantile)\n",
    "\n",
    "# Mostramos cual el número de votos de corte a partir del cuál sí tomamos películas\n",
    "print(\"Cuantil de voto\", str(quantile) + \":\", vote_quantile)\n",
    "\n",
    "# Nos quedamos sólo con ese 33% de películas\n",
    "df_movies_original = df_movies_original.loc[df_movies_original[\"vote_count\"] >= vote_quantile]\n",
    "\n",
    "#Mostramos las dimensiones después de quitar películas\n",
    "print(\"Dimensiones tras quitar películas:\", df_movies_original.shape)\n",
    "\n",
    "#Dejamos en el dataset los géneros de las películas en forma de lista para trabajar más cómodamente con ellos\n",
    "df_movies_original[\"genres\"] = df_movies_original[\"genres\"].apply(literal_eval)\n",
    "df_movies_original[\"genres\"] = df_movies_original[\"genres\"].apply(lambda genres: list(map(lambda genre: genre[\"name\"], genres)))\n",
    "\n",
    "# Guardamos el dataset \"limpio\" en el fichero \"movies_catalog_clean.csv\"\n",
    "df_movies_original.to_csv(\"movies_catalog_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b95a2",
   "metadata": {},
   "source": [
    "Cargamos y limpiamos la tabla con los créditos de las películas (tiene información relevante para nosotros como el reparto o el director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564d7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits_original = pd.read_csv(\"credits.csv\")\n",
    "\n",
    "# Eliminamos también repeticiones de ids en los créditos de las películas\n",
    "df_credits_original = df_credits_original.drop_duplicates(subset = ['id'])\n",
    "\n",
    "df_credits_original.to_csv(\"credits_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df5265",
   "metadata": {},
   "source": [
    "Cargamos las tablas limpias que hemos guardado en el fichero para comprobar que todo está bien y trabajar sobre ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5c326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"movies_catalog_clean.csv\")\n",
    "df_credits = pd.read_csv(\"credits_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b68222",
   "metadata": {},
   "source": [
    "Hacemos un join entre la tabla con las películas y la que tiene sus créditos según el identificador de película. utilizaremos variables que provienen de ambas tablas y necesitamos primero su correspondencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38a904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_movies.merge(df_credits, on ='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b12c8",
   "metadata": {},
   "source": [
    "En el modelo, tendremos también en cuenta palabras clave sobre la película. Estas palabras clave están en un tercer dataset que cargamos, limpiamos y unimos a los dos anteriores (de nuevo un join) a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7db4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos IDs repetidos (los hay)\n",
    "df_keywords = pd.read_csv(\"keywords.csv\").drop_duplicates(subset = ['id'])\n",
    "df = df.merge(df_keywords, on ='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8ff58",
   "metadata": {},
   "source": [
    "Convertimos las columnas que vamos a usar en el modelo a objetos python mediante la función \"literal_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7574ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df[feature] = df[feature].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c03d79",
   "metadata": {},
   "source": [
    "Creamos una función  que, dado el equipo de la película, extrae a los directores (puede haber varios al existir codirectores). Y otra función que datda una lista de lista de personas devuelve una lista con los n primeros nombres de las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c026035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def director(crew):\n",
    "    for person in crew:\n",
    "        if person['job'] == 'Director':\n",
    "            return [person['name']]\n",
    "    return np.nan\n",
    "\n",
    "def getTop(n, mList):\n",
    "    if isinstance(mList, list):\n",
    "        names = list(map(lambda person: person[\"name\"], mList))\n",
    "        names = names[:n]\n",
    "        return names\n",
    "    #Devolvemos la lista vacía en caso de datos incorrectos\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a70df5",
   "metadata": {},
   "source": [
    "Observamos la salida al extraer el director de cada película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f1eadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [John Lasseter]\n",
       "1           [Joe Johnston]\n",
       "2          [Howard Deutch]\n",
       "3        [Forest Whitaker]\n",
       "4          [Charles Shyer]\n",
       "               ...        \n",
       "14727      [Colin Minihan]\n",
       "14728         [Beth David]\n",
       "14729         [Larry Shaw]\n",
       "14730     [Georges Méliès]\n",
       "14731     [Georges Méliès]\n",
       "Name: crew, Length: 14732, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['crew'].apply(director)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a0df1",
   "metadata": {},
   "source": [
    "Utilizando las funciones anteriores modificamos el dataset para crear una columna \"director\" con los nombres de los directores de la película, dejar en la columna \"cast\" los 3 actores principales de la película (el orden de aparición en el dataset sabemos que es de mas a menos importante para la película), dejar en la columna \"keywords\" las 10 palabras clave principales y en la columna \"genres\" los hasta 10 géneros principales de la película (en general no tienen tantos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e20b8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfContentBased = pd.DataFrame()\n",
    "dfContentBased['id'] = df['id']\n",
    "dfContentBased['director'] = df['crew'].apply(director)\n",
    "\n",
    "featuresTop = [('cast', 3), ('keywords', 10)]\n",
    "for feature, topLimit in featuresTop:\n",
    "    dfContentBased[feature] = df[feature].apply(partial(getTop, topLimit))\n",
    "    \n",
    "dfContentBased[\"genres\"] = df[\"genres\"].apply(lambda l: l[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b6e58",
   "metadata": {},
   "source": [
    "Creamos una función que compacta los datos convirtiéndolos a minúscula y eliminar especios entre palabras. **No queremos que al calcular similitudes el director John Lasseter y John Waters en común el término John, pues son personas distintas**. Para que los términos sean los directores completos (e igual con actores, palabras clave o género) eliminamos los espacios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e07d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_data(data):\n",
    "    if isinstance(data, list):\n",
    "        return [str.lower(element.replace(\" \", \"\")) for element in data]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "features = [\"director\", \"cast\", \"keywords\", \"genres\"]\n",
    "for feature in features:\n",
    "    dfContentBased[feature] = dfContentBased[feature].apply(compact_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762211c8",
   "metadata": {},
   "source": [
    "Observamos el resultado de las primeras filas tras compactar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc52d620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[johnlasseter]</td>\n",
       "      <td>[tomhanks, timallen, donrickles]</td>\n",
       "      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n",
       "      <td>[animation, comedy, family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[joejohnston]</td>\n",
       "      <td>[robinwilliams, jonathanhyde, kirstendunst]</td>\n",
       "      <td>[boardgame, disappearance, basedonchildren'sbo...</td>\n",
       "      <td>[adventure, fantasy, family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[howarddeutch]</td>\n",
       "      <td>[waltermatthau, jacklemmon, ann-margret]</td>\n",
       "      <td>[fishing, bestfriend, duringcreditsstinger, ol...</td>\n",
       "      <td>[romance, comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[forestwhitaker]</td>\n",
       "      <td>[whitneyhouston, angelabassett, lorettadevine]</td>\n",
       "      <td>[basedonnovel, interracialrelationship, single...</td>\n",
       "      <td>[comedy, drama, romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[charlesshyer]</td>\n",
       "      <td>[stevemartin, dianekeaton, martinshort]</td>\n",
       "      <td>[baby, midlifecrisis, confidence, aging, daugh...</td>\n",
       "      <td>[comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          director                                            cast  \\\n",
       "0    862    [johnlasseter]                [tomhanks, timallen, donrickles]   \n",
       "1   8844     [joejohnston]     [robinwilliams, jonathanhyde, kirstendunst]   \n",
       "2  15602    [howarddeutch]        [waltermatthau, jacklemmon, ann-margret]   \n",
       "3  31357  [forestwhitaker]  [whitneyhouston, angelabassett, lorettadevine]   \n",
       "4  11862    [charlesshyer]         [stevemartin, dianekeaton, martinshort]   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [jealousy, toy, boy, friendship, friends, riva...   \n",
       "1  [boardgame, disappearance, basedonchildren'sbo...   \n",
       "2  [fishing, bestfriend, duringcreditsstinger, ol...   \n",
       "3  [basedonnovel, interracialrelationship, single...   \n",
       "4  [baby, midlifecrisis, confidence, aging, daugh...   \n",
       "\n",
       "                         genres  \n",
       "0   [animation, comedy, family]  \n",
       "1  [adventure, fantasy, family]  \n",
       "2             [romance, comedy]  \n",
       "3      [comedy, drama, romance]  \n",
       "4                      [comedy]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfContentBased.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ae6c4",
   "metadata": {},
   "source": [
    "A continuación concatenamos, separando con espacios, las distintas variables que representarán a la película al calcular similitudes de nuestra películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "263af510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinFeatures(features, dataList):\n",
    "    joinedResult = \"\"\n",
    "    for feature in features:\n",
    "        joinedResult += \" \".join(dataList[feature]) + \" \"\n",
    "    # Quitamos el último espacio, que sobra al no separar palabras\n",
    "    joinedResult = joinedResult[:-1]\n",
    "    return joinedResult\n",
    "\n",
    "dfContentBased['featuresSoup'] = dfContentBased.apply(partial(joinFeatures, features), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a7e0a",
   "metadata": {},
   "source": [
    "Mostramos el resultado para la primera película y vemos cómo la frase que la representa tiene en cuenta su director, sus actores principales, algunas palabras clave que la describen y los géneros a los que pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f63c3170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'johnlasseter tomhanks timallen donrickles jealousy toy boy friendship friends rivalry boynextdoor newtoy toycomestolife animation comedy family'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfContentBased['featuresSoup'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309f832",
   "metadata": {},
   "source": [
    "Vectorizamos las descripciones que acabamos de crear para las películas de nuestro dataset. **Como medida, utilizamos la frecuencia de aparición (CountVectorized) en lugar de TF-IDF, porque no queremos penalizar que un director o un actor aparezca en muchas películas**. Si un director o un actor aparece en muchas películas será que es muy famoso y relevante para la comparación; no tiene sentido introducir el factor IDF que lo penalice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e885f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countMatrix = CountVectorizer().fit_transform(dfContentBased['featuresSoup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df156b",
   "metadata": {},
   "source": [
    "Calculamos la similitud entre cada par de vectores de películas k-dimensionales (siendo k el tamaño del vocabulario resultante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78ae85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "simMatrix = cosine_similarity(countMatrix, countMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebc22f",
   "metadata": {},
   "source": [
    "Ordenamos los valores de similitud para cada fila de la matriz de mayor a menor y los sustituimos por el índice que ocupaban antes de ordenar la matriz (simMatrix, axis=1), en todas las filas eliminamos el primera valor (la similitus máxima=1.0 siempre la tenemos con nosotros mismos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "876f8100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8453,  2046, 11452, ...,  7983,  7981, 14731],\n",
       "       [12248, 11189,  6747, ...,  7871,  7870,  7365],\n",
       "       [ 2258,  1148,  1011, ...,  5894,  5895, 14731],\n",
       "       ...,\n",
       "       [ 4038, 12081, 14386, ..., 11723,  6780, 14731],\n",
       "       [11887, 14715, 14731, ..., 11341, 11339,  4807],\n",
       "       [14730, 14632, 14715, ...,  8730,  8729,     0]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendIndexes = np.argsort(simMatrix, axis=1)\n",
    "recommendIndexes = recommendIndexes[:, -2::-1]\n",
    "recommendIndexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33f04f",
   "metadata": {},
   "source": [
    "En lugar de posiciones en el array, queremos tener los IDs de las películas correspondientes a dichas posiciones. Hacemos un mapeo en la matriz por filas para que en lugar de 8453 ponga 10193, siendo 10193 el ID de la película que está en la posición 8453 de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1a34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10193,    863, 256835, ...,  18533,  17336,  49280], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfContentBased['id'][recommendIndexes[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90b68552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10193,    863, 256835, ...,  18533,  17336,  49280],\n",
       "       [262788,  25475,   9992, ...,  11914,    761,   9029],\n",
       "       [ 11520,  27472,  18080, ...,     26,   2026,  49280],\n",
       "       ...,\n",
       "       [ 18736,  50794, 444706, ..., 309299,  10075,  49280],\n",
       "       [  2963, 104700,  49280, ..., 246860, 253295,  29455],\n",
       "       [ 49279, 104466, 104700, ...,  46138,  16987,    862]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idsMaxToMin = np.array(list(map(lambda indexes: dfContentBased['id'][indexes].values, recommendIndexes)))\n",
    "idsMaxToMin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe39924",
   "metadata": {},
   "source": [
    "Guardamos la matriz en el fichero externo \"contentBasedModel.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "274c5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "save('contentBasedModel.npy', idsMaxToMin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
